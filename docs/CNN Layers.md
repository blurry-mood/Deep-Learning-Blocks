## Input Aware Layer
This layer takes an input tensor (B, C, H, W) and applies conv2d operation to it, but with different kernels for every sample in the batch.

The name comes from the fact that this layer uses customized convolution kernels for each image (or feature map) in the batch. Instead of applying the same kernels for all input images, it uses kernels provided by the Hidden layer (specified below).  
Thus, it's aware of the input's content.

### **Architecture**:
![InputAware Layer](/docs/imgs/InputAware.png "Architecture of the InputAware Layer.")

* The rectangle with the red dotted border is the Hidden Layer. It generates kernels that are customized for every image in the batch.
* The rectangle with the green solid border is the ConvBlock Layer. It takes as input a tensor with `in_channels` channels, and returns a tensor with `out_channels`.
* The Linears is an optional layer. If used, it applies a linear transformation to each kernel (for each kernel there is a independant Linear Layer) and returns a new kernel with the same shape.

### **How to use**:
1- Import ConvBlock:
> from deepblocks.CNN.InputAware import ConvBlock

2- Create an instance:
>  conv_block = ConvBlock(in_channels, out_channels, mid_channels, drop_pb, kernel_size, use_linear)
* mid_channels: the number of output channels after applying the first conv2d layer in the Hidden layer.
* use_linear: if True, Linears is applied to the set of kernels.
* kernel_size: the desired size of the kernels to apply to the input tensor.
* drop_pb: the probability assfociated with the Dropout layer.
### **Remarks**:
* NOT YET IMPLEMENTED: The last conv2d operator (that takes kernels from the Hidden layer) doesn't use bias since it's not generated by Hidden. 
* When tested on MNIST, it converges really fast compared to a vanilla CNN, in 1 epoch the former reaches a validation CELoss of 0.07 while the latter reaches 0.7 for CNN by then.

## Funnel ReLU (FReLU)
This layer takes an input tensor I = (B, C, H, W), applies a spatial transformation O = (B, C, H, W), then returns the maximum value between I and O in an element-wise way.

### **Formula**:
$f(x_{c,i,j}) = max(x_{c,i,j}, T(x_{c,i,j}))$
* $T(x_{c,i,j})$ is the convolution operator with a kernel *p* applied to a window centered on $x_{c,i,j}$.   
Please note that *p* a window of *learnable* parameters, and it is shared in the same channel.

### **How to use**:
1- Import FReLU:
> from deepblocks.CNN.FReLU import FReLU

2- Create an instance:
>  frelu = FReLU(in_channels, kernel_size=3)
* in_channels: The input channels.
* kernel_size: The dimension of the kernel *p*. It could be an integer or a tuple of two integers.   
  Note that the dimensions must be odd numbers.

### **Remarks**:
* For more insights, check the original paper: [Funnel Activation for Visual Recognition
](https://arxiv.org/abs/2007.11824)

